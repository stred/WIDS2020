{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WIDS Week 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1g5zG_sRz2bfSsTrMfelDqgqBNL8C7QaQ",
      "authorship_tag": "ABX9TyMc2PxhOILZKyxpkYoIQPEs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbYaSoz-E7Mv",
        "colab_type": "text"
      },
      "source": [
        "# Women in Data Science\n",
        "## Week 4 - Model Evaluation\n",
        "\n",
        "### Stephen Redmond\n",
        "Enterprise Insight Studio Lead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_6xr2A-BoWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect to my Google Drive\n",
        "from google.colab import drive\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_UPKRg-BtOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls '/content/drive/My Drive/WIDS'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUXfc5uIKajR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll do some plotting later\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUzNgwkgFhlC",
        "colab_type": "text"
      },
      "source": [
        "#Loading the DataFrame from a CSV file using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzuDEVXSCV27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the pandas library\n",
        "# Traditionally, this is loaded and named as \"pd\"\n",
        "import pandas as pd\n",
        "# The numpy library is traditionally \"np\"\n",
        "import numpy as np\n",
        "\n",
        "# Titanic data from https://www.kaggle.com/c/titanic/data\n",
        "# Load the Titanic data file from my Google Drive\n",
        "df = pd.read_csv('/content/drive/My Drive/WIDS/titanic/train.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb76Ue5wf79N",
        "colab_type": "text"
      },
      "source": [
        "# Data Dictionary\n",
        "| Variable | Definition                                 | Key                                            |\n",
        "|----------|--------------------------------------------|------------------------------------------------|\n",
        "| survival | Survival                                   | 0 = No, 1 = Yes                                |\n",
        "| pclass   | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
        "| sex      | Sex                                        |                                                |\n",
        "| Age      | Age in years                               |                                                |\n",
        "| sibsp    | # of siblings / spouses aboard the Titanic |                                                |\n",
        "| parch    | # of parents / children aboard the Titanic |                                                |\n",
        "| ticket   | Ticket number                              |                                                |\n",
        "| fare     | Passenger fare                             |                                                |\n",
        "| cabin    | Cabin number                               |                                                |\n",
        "| embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNlXy0tcYk2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Have a quick look\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkmMtvlxh0wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# And the non-numeric fields\n",
        "df[[\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"]].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoyBBHMljoHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some of these fields are less than useful:\n",
        "# - Cabin has many missing values\n",
        "# - Name, Ticket and PassengerId have too many unique values\n",
        "df = df.drop(columns = ['Cabin','Name','Ticket','PassengerId'])\n",
        "\n",
        "# The Embarked field has 2 missing - let's just assume it was Southampton\n",
        "df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
        "\n",
        "# Age has NaN values ... what should we do?\n",
        "df['Age'].fillna(df['Age'].mode()[0], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xUw5InL_FGn0"
      },
      "source": [
        "# Model evaluation\n",
        "We have built our models, what are the ways we can evaluate their performance?\n",
        "\n",
        "Let's start with classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QuvytfjOpUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model - we've done this a lot already\n",
        "\n",
        "# Create a new feature called FamilySize\n",
        "df['FamilySize'] = df['SibSp'] + df['Parch'] \n",
        "df['IsAlone'] = 0\n",
        "df.loc[df['FamilySize'] == 0, 'IsAlone'] = 1\n",
        "\n",
        "# Splitting into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X = train_test_split(df, test_size = 0.2) \n",
        "\n",
        "# Train my models with a small # of features\n",
        "from sklearn import tree\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "\n",
        "X = pd.get_dummies(train_X[[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"FamilySize\"]],drop_first=True) \n",
        "y = train_X[\"Survived\"]\n",
        "dt = dt.fit(X, y)\n",
        "X_test = pd.get_dummies(test_X[[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"FamilySize\"]],drop_first=True) #.to_numpy()\n",
        "y_test = test_X[\"Survived\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcr0ahC5neNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the predictions and generate a confusion matrix\n",
        "y_pred = dt.predict(X_test)\n",
        "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRAkhXraJ0f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install scikit-plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxNsDMSlJsny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Or a more graphical one?\n",
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred, title=\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh7YDZRILEUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQMmuc60qj3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcualte F1 score: F1 = 2 * (precision * recall) / (precision + recall)\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, auc, accuracy_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "resTable=[['Accuracy  :', acc]]\n",
        "prec = precision_score(y_test, y_pred)\n",
        "resTable.append(['Precision :', prec])\n",
        "recall = recall_score(y_test, y_pred)\n",
        "resTable.append(['Recall    :', recall])\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "resTable.append(['F1 Score  :', f1])\n",
        "\n",
        "# ROC / AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "AreaUnderCurve = auc(fpr, tpr)\n",
        "resTable.append(['FPR       :', fpr])\n",
        "resTable.append(['TPR       :', tpr])\n",
        "resTable.append(['Threshold :', thresholds])\n",
        "resTable.append(['AUC       :', AreaUnderCurve])\n",
        "\n",
        "print([print(y[0] + '\\t' + str(y[1])) for y in resTable])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aKWpu9QjeReJ",
        "colab": {}
      },
      "source": [
        "# Plot the ROC Curve\n",
        "\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=2, label='ROC curve (area = %0.2f)' % AreaUnderCurve)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ziT6lwjeRsgR"
      },
      "source": [
        "# Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxQakW09D6pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Need to scale our data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit our scaler to the OneHot encoded data and transform it\n",
        "X = scaler.fit_transform(pd.get_dummies(train_X[[\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"FamilySize\"]],drop_first=True)) \n",
        "y = train_X[\"Fare\"]\n",
        "X_test = pd.get_dummies(test_X[[\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"FamilySize\"]],drop_first=True) #.to_numpy()\n",
        "y_test = test_X[\"Fare\"]\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8GrjB4BEfPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(X, y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95pBlJqCE3K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"R^2: \" + str(reg.score(X, y)) + \"\\nCoefficients: \" + str(reg.coef_) + \"\\nIntercept:\" + str(reg.intercept_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pQsFXbuFk4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict using the model\n",
        "y_pred = reg.predict(X_test_scaled)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-CZOUwkZVOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "rmse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(rmse, mae)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNiXIiPuMhze",
        "colab_type": "text"
      },
      "source": [
        "# Hyper parameter tuning\n",
        "Manual or automatic changing the parameters used to train a model until we get the best results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFAktDgqaBZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the RF Classifier module\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf=RandomForestClassifier()\n",
        "\n",
        "# Setup the data with dummy coding\n",
        "X = pd.get_dummies(train_X[[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"FamilySize\"]],drop_first=True) \n",
        "y = train_X[\"Survived\"]\n",
        "X_test = pd.get_dummies(test_X[[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"FamilySize\"]],drop_first=True) \n",
        "y_test = test_X[\"Survived\"]\n",
        "\n",
        "# import the GridSearch module\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Setup some parameters to run through\n",
        "param_grid = {'max_depth': np.arange(1, 30, 3),\n",
        "             'criterion': ['gini', 'entropy']}\n",
        "\n",
        "# Find the best combo of parameters\n",
        "my_tuned_tree = GridSearchCV(RandomForestClassifier(), param_grid) #, scoring='f1_weighted')\n",
        "my_tuned_tree.fit(X, y)\n",
        "print(my_tuned_tree.best_score_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkKBOJ3bbctR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict using the tuned tree\n",
        "y_pred = my_tuned_tree.predict(X_test)\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred, title=\"Confusion Matrix\")\n",
        "plt.show()\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UJtGm3JSznb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What are the scoring options for the Grid Search?\n",
        "import sklearn.metrics as skm\n",
        "skm.SCORERS.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhITPp2iTm46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}